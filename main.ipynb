{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part for colab\n",
    "# !git clone https://github.com/REU-DS-CLUB/Face_id_and_detection/\n",
    "# import os\n",
    "# os.chdir('/content/Face_id_and_detection')\n",
    "# !pip install -q comet-ml facenet-pytorch timm # для гугл колаба не нужно скачивать все из requirements.txt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import timm\n",
    "\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "import src.models as mdls\n",
    "import src.utils as utils\n",
    "\n",
    "# Face recognition imports\n",
    "from src.models import Triplet\n",
    "from src.utils import TripletLoss\n",
    "\n",
    "\n",
    "#downloading datasets\n",
    "config = utils.get_options()\n",
    "\n",
    "\n",
    "if config['use_colab']:\n",
    "    utils.colab()\n",
    "else:\n",
    "    utils.check_if_datasets_are_downloaded()\n",
    "\n",
    "import src.dataloaders as dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = config['img_size']\n",
    "\n",
    "# Задаем директорию для checkpoints\n",
    "checkpoint_dir = \"checkpoints/\"\n",
    "\n",
    "# Проверяем, есть ли уже такая директори, если нет, создаем\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "#определяем, доступен ли cude\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection setup\n",
    "\n",
    "# Задаем размер тестовой выборки для разделения данных на обучение и тест\n",
    "test_size = 0.1\n",
    "\n",
    "# Задаем скорость обучения для оптимизатора\n",
    "det_lr = 1e-3\n",
    "\n",
    "# Создаем экземпляр модели для обнаружения лиц (InspectorGadjet предполагается, что это название модели)\n",
    "detection_model = mdls.InspectorGadjet()\n",
    "\n",
    "# Получаем загрузчики данных для обучения и тестирования модели\n",
    "train_detection_dataloader, test_detection_dataloader = dataloaders.get_train_test_dataloaders(dataloaders.dataset, test_size=test_size)\n",
    "\n",
    "# Задаем функцию потерь для обучения модели (в данном случае Mean Squared Error Loss)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Задаем оптимизатор (Adam) для обновления параметров модели\n",
    "optimizer = torch.optim.Adam(detection_model.parameters(), lr=det_lr)\n",
    "\n",
    "# Перемещаем модель на устройство (например, GPU, если доступен)\n",
    "detection_model.to(device)\n",
    "\n",
    "# Задаем шедулер для управления скоростью обучения (уменьшение скорости обучения на каждом шаге)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Задаем ранний остановщик для прекращения обучения, если потери не уменьшаются в течение некоторого времени\n",
    "early_stopper = utils.EarlyStopping(patience=10, min_delta=0.01)\n",
    "\n",
    "# Выводим количество элементов в обучающем загрузчике данных\n",
    "print(len(train_detection_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to check how albumentation works\n",
    "# batch = next(iter(train_detection_dataloader))\n",
    "# utils.plot_images_with_bboxes(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считывание параметров обучения с файла config.yaml\n",
    "det_epochs = config['detection_epochs']\n",
    "det_logging = config['detection_logging']\n",
    "log_interval = config[\"detection_log_wieghts_interval\"]\n",
    "\n",
    "# переменная с путем к изображению для \"валидации\"\n",
    "test_img_path = ''\n",
    "\n",
    "if det_logging: \n",
    "    # для логирования эксперимента понадобится файл с ключом к эксперименту из лк в comet-ml\n",
    "    with open('secrets.json') as secrets_file:\n",
    "        secrets = json.load(secrets_file)\n",
    "\n",
    "    # init experimenxt\n",
    "    experiment = Experiment(\n",
    "        api_key=secrets[\"api_key\"],\n",
    "        project_name=secrets[\"project_name\"],\n",
    "        workspace=\"reu-ds-club\", \n",
    "        tags=[\"detection\"],\n",
    "    )\n",
    "\n",
    "    # считывание параметров обучения с файла config.yaml\n",
    "    hyper_params = {\n",
    "        \"model_name\": config[\"model\"],\n",
    "        \"use_colab\": config['use_colab'], \n",
    "        \"epochs\": det_epochs,\n",
    "        \"batch_size\": config['batch_size'], \n",
    "        \"image_size\": config['img_size'], \n",
    "    }\n",
    "\n",
    "    experiment.log_parameters(hyper_params)\n",
    "\n",
    "for epoch in range(det_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for sample in (pbar := tqdm(train_detection_dataloader)):\n",
    "\n",
    "        img, box = sample[0].to(device), sample[1].to(device)\n",
    "        img = img.to(torch.float32)\n",
    "        box = box.to(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = detection_model(img)\n",
    "        loss = loss_fn(pred, box)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # уменьшение learning rate со временем\n",
    "    scheduler.step()\n",
    "\n",
    "    # Валидация модели на тестовом датасете\n",
    "    val_loss = utils.validate_model(detection_model, test_detection_dataloader, loss_fn, device)\n",
    "\n",
    "    print(f\"Epoch: {epoch}\\tLoss: {epoch_loss / len(train_detection_dataloader)}\\tVal loss: {val_loss}\")\n",
    "\n",
    "    # выводить промежуточный результат работы нейронной сети с помощью загруженного изображения. \n",
    "    # Нужно лишь указать пусть к файлу .png в переменную test_img_path\n",
    "    # Результат будет в папке results\n",
    "    if test_img_path is not \"\":\n",
    "        utils.save_img_after_epoch(test_img_path, detection_model, epoch, device)\n",
    "\n",
    "    # Функция ранней остановки, если нейронная сеть перестает обучаться, то есть val_loss не падает \n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    # Сохранение весов модели после каждой эпохи\n",
    "    checkpoint_filename = os.path.join(checkpoint_dir, f\"{epoch}_checkpoint_detection.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': detection_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "    }, checkpoint_filename)\n",
    "\n",
    "    #логирование метрики в comet-ml\n",
    "    if det_logging:\n",
    "        experiment.log_metric(\"loss\", epoch_loss, step=epoch)\n",
    "    \n",
    "    # logging model weights (accorging to log_interval + last epoch)\n",
    "    if det_logging and (epoch % log_interval == 0 or epoch == det_epochs-1):\n",
    "        torch.save(detection_model, 'det_model.pth')\n",
    "        experiment.log_model(name = f\"model-epoch-{epoch}\", file_or_folder = 'det_model.pth', file_name = f\"det-model-epoch-{epoch}\")\n",
    "        experiment.log_asset(file_data = 'det_model.pth', file_name = f\"det_model-epoch-{epoch}\")\n",
    "        print(\"save model\")\n",
    "\n",
    "\n",
    "if det_logging:\n",
    "    experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for face recognition model training\n",
    "\n",
    "# Устанавливаем скорость обучения (learning rate) для оптимизатора\n",
    "lr = 1e-3\n",
    "\n",
    "# Создаем модель студента для обучения (efficientnet_b1 с заменой классификатора)\n",
    "student = timm.create_model('efficientnet_b1', pretrained=True)\n",
    "student.classifier = nn.Linear(student.classifier.in_features, 512)\n",
    "student = student.to(device)\n",
    "\n",
    "# Создаем модель для триплет-обучения на основе студента\n",
    "triplet_model = Triplet(student).to(device)\n",
    "\n",
    "# Создаем модель учителя для распознавания лиц (InceptionResnetV1 с предобученными весами)\n",
    "teacher = InceptionResnetV1(pretrained='vggface2').to(device)\n",
    "\n",
    "# Задаем функцию потерь для обучения распознаванию лиц (Triplet Loss)\n",
    "loss_for_recognition = TripletLoss(margin=5)\n",
    "\n",
    "# Задаем оптимизатор (Adam) для обновления параметров модели\n",
    "optimizer = torch.optim.Adam(triplet_model.parameters(), lr=lr)\n",
    "\n",
    "# Задаем критерий для распознавания (Mean Squared Error Loss)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Задаем шедулер для управления скоростью обучения (уменьшение скорости обучения на каждом шаге)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Задаем ранний остановщик для прекращения обучения, если потери не уменьшаются в течение некоторого времени\n",
    "early_stopper = utils.EarlyStopping(patience=10, min_delta=0.01)\n",
    "\n",
    "# Получаем загрузчик данных для обучения распознаванию лиц\n",
    "recognition_dataloader = dataloaders.recognition_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считывание параметров обучения с файла config.yaml\n",
    "rec_epochs = config['recognition_epochs']\n",
    "rec_logging = config['recognition_logging']\n",
    "rec_log_interval = config[\"recognition_log_wieghts_interval\"]\n",
    "\n",
    "if rec_logging: \n",
    "    # для логирования эксперимента понадобится файл с ключом к эксперименту из лк в comet-ml\n",
    "    with open('secrets.json') as secrets_file:\n",
    "        secrets = json.load(secrets_file)\n",
    "\n",
    "    # init experimenxt\n",
    "    experiment = Experiment(\n",
    "        api_key=secrets[\"api_key\"],\n",
    "        project_name=secrets[\"project_name\"],\n",
    "        workspace=\"reu-ds-club\", \n",
    "        tags=[\"recognition\"],\n",
    "    )\n",
    "\n",
    "    # считывание параметров обучения с файла config.yaml\n",
    "    hyper_params = {\n",
    "        \"model_name\": config[\"model\"],\n",
    "        \"use_colab\": config['use_colab'], \n",
    "        \"epochs\": rec_epochs,\n",
    "        \"batch_size\": config['batch_size'], \n",
    "        \"image_size\": config['img_size'], \n",
    "    }\n",
    "\n",
    "    experiment.log_parameters(hyper_params)\n",
    "\n",
    "for epoch in range(rec_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_distilation_loss = 0\n",
    "    for  triplet in (pbar := tqdm(recognition_dataloader)):\n",
    "\n",
    "        anc, pos, neg = triplet\n",
    "\n",
    "        preds = triplet_model(anc.to(device), pos.to(device), neg.to(device))\n",
    "        \n",
    "        triplet_loss = loss_for_recognition(*preds)\n",
    "\n",
    "        triplet_encoder_output = triplet_model.encoder(anc.to(device))\n",
    "        outputs_facenet = teacher(anc.to(device))\n",
    "        distillation_loss = criterion(triplet_encoder_output, outputs_facenet)\n",
    "\n",
    "        # get total loss\n",
    "        total_loss = triplet_loss + distillation_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += total_loss.item()\n",
    "        epoch_distilation_loss += distillation_loss.item()\n",
    "    \n",
    "    # уменьшение learning rate со временем\n",
    "    scheduler.step()\n",
    "\n",
    "    # Функция ранней остановки, если нейронная сеть перестает обучаться, то есть val_loss не падает \n",
    "    early_stopper(epoch_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    \n",
    "    print(f'{epoch} | EPOCH LOSS: {total_loss} | DISTILATOIN LOSS: {epoch_distilation_loss}')\n",
    "    \n",
    "    # Сохранение весов модели после каждой эпохи\n",
    "    checkpoint_filename = os.path.join(checkpoint_dir, f\"{epoch}_checkpoint_recognition.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': triplet_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "    }, checkpoint_filename)\n",
    "\n",
    "    #логирование метрики в comet-ml\n",
    "    if rec_logging:\n",
    "        experiment.log_metric(\"loss\", epoch_loss, step=epoch)\n",
    "    \n",
    "    # logging model weights (accorging to log_interval + last epoch)\n",
    "    if rec_logging and (epoch % log_interval == 0 or epoch == rec_epochs-1):\n",
    "        torch.save(triplet_model, 'rec_model.pth')\n",
    "        experiment.log_model(name = f\"rec_model-epoch-{epoch}\", file_or_folder = 'rec_model.pth', file_name = f\"rec_model-epoch-{epoch}\")\n",
    "        experiment.log_asset(file_data = 'rec_model.pth', file_name = f\"rec_model-epoch-{epoch}\")\n",
    "        print(\"save model\")\n",
    "\n",
    "\n",
    "if rec_logging:\n",
    "    experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
