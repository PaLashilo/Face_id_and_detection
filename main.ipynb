{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving kaggle file\n",
      "\n",
      "all datasets are in place\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import src.models as mdls\n",
    "import src.utils as utils\n",
    "\n",
    "config = utils.get_options()\n",
    "if config['use_colab']:\n",
    "    utils.colab()\n",
    "else:\n",
    "    utils.check_if_datasets_are_downloaded()\n",
    "\n",
    "import src.dataloaders as dataloaders\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = config['img_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4856"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mdls.InspectorGadjet()\n",
    "dataloader = dataloaders.dataloader\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a directory to save the checkpoints\n",
    "checkpoint_dir = \"checkpoints/\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "import os\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.MSELoss()\n",
    "loss_fn = mdls.combined_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.to(device)\n",
    "# loss_fn.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4856"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4856 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 91/4856 [00:14<12:49,  6.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andreisuhov/Desktop/DL projects/Face_id_and_detection/main.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreisuhov/Desktop/DL%20projects/Face_id_and_detection/main.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreisuhov/Desktop/DL%20projects/Face_id_and_detection/main.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     epoch_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andreisuhov/Desktop/DL%20projects/Face_id_and_detection/main.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m (pbar \u001b[39m:=\u001b[39m tqdm(dataloader)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreisuhov/Desktop/DL%20projects/Face_id_and_detection/main.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         img, box \u001b[39m=\u001b[39m sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), sample[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreisuhov/Desktop/DL%20projects/Face_id_and_detection/main.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataset.py:243\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[0;32m~/Desktop/DL projects/Face_id_and_detection/src/dataloaders.py:202\u001b[0m, in \u001b[0;36mTenThousandFaceDataSet.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    198\u001b[0m     image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mconvert(\u001b[39m'\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[39m# Извлекаем координаты bbox из CSV файла\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m x1, y1, x2, y2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49miloc[idx, \u001b[39m1\u001b[39;49m:]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m    203\u001b[0m width, height \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39msize\n\u001b[1;32m    204\u001b[0m \u001b[39m# Создаем ограничивающий прямоугольник (bbox)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:1596\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1594\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[1;32m   1595\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m-> 1596\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[1;32m   1598\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:1024\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[39mreturn\u001b[39;00m section\n\u001b[1;32m   1023\u001b[0m         \u001b[39m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(section, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)[new_key]\n\u001b[1;32m   1026\u001b[0m \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mnot applicable\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:1091\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1090\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m-> 1091\u001b[0m     check_dict_or_set_indexers(key)\n\u001b[1;32m   1092\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(key) \u001b[39mis\u001b[39;00m \u001b[39mtuple\u001b[39m:\n\u001b[1;32m   1093\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mlist\u001b[39m(x) \u001b[39mif\u001b[39;00m is_iterator(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:2624\u001b[0m, in \u001b[0;36mcheck_dict_or_set_indexers\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m   2613\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2614\u001b[0m     \u001b[39misinstance\u001b[39m(key, \u001b[39mset\u001b[39m)\n\u001b[1;32m   2615\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m)\n\u001b[1;32m   2616\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mset\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   2617\u001b[0m ):\n\u001b[1;32m   2618\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2619\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a set as an indexer is not supported. Use a list instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2620\u001b[0m     )\n\u001b[1;32m   2622\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2623\u001b[0m     \u001b[39misinstance\u001b[39m(key, \u001b[39mdict\u001b[39m)\n\u001b[0;32m-> 2624\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39;49m(key, \u001b[39mtuple\u001b[39;49m)\n\u001b[1;32m   2625\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   2626\u001b[0m ):\n\u001b[1;32m   2627\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2628\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a dict as an indexer is not supported. Use a list instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2629\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = config['epochs']\n",
    "logging = config['logging']\n",
    "log_interval = config[\"log_wieghts_interval\"]\n",
    "\n",
    "\n",
    "if logging: \n",
    "    # read secrets for cometml logging\n",
    "    with open('secrets.json') as secrets_file:\n",
    "        secrets = json.load(secrets_file)\n",
    "\n",
    "    # init experimenxt\n",
    "    experiment = Experiment(\n",
    "        api_key=secrets[\"api_key\"],\n",
    "        project_name=secrets[\"project_name\"],\n",
    "        workspace=\"reu-ds-club\", \n",
    "    )\n",
    "\n",
    "    hyper_params = {\n",
    "        \"model_name\": config[\"model\"],\n",
    "        \"use_colab\": config['use_colab'], \n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": config['batch_size'], \n",
    "        \"image_size\": config['img_size'], \n",
    "    }\n",
    "\n",
    "    experiment.log_parameters(hyper_params)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for sample in (pbar := tqdm(dataloader)):\n",
    "\n",
    "        img, box = sample[0].to(device), sample[1].to(device)\n",
    "        img = img.to(torch.float32)\n",
    "\n",
    "        box = box.to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        # loss = loss_fn(pred, box)\n",
    "\n",
    "        loss = loss_fn(pred[0], pred[1], box)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch}\\tLoss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "    checkpoint_filename = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "    }, checkpoint_filename)\n",
    "\n",
    "    if logging:\n",
    "        experiment.log_metric(\"loss\", epoch_loss, step=epoch)\n",
    "    \n",
    "    # logging model weights (accorging to log_interval + last epoch)\n",
    "    if logging and (epoch % log_interval == 0 or epoch == epochs-1):\n",
    "        torch.save(model, 'model.pth')\n",
    "        experiment.log_model(name = f\"model-epoch-{epoch}\", file_or_folder = 'model.pth', file_name = f\"model-epoch-{epoch}\")\n",
    "        experiment.log_asset(file_data = 'model.pth', file_name = f\"model-epoch-{epoch}\")\n",
    "        print(\"save model\")\n",
    "\n",
    "\n",
    "if logging:\n",
    "    experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
